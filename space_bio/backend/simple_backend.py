#!/usr/bin/env python3
"""
Simple backend without database for testing the chatbot functionality.
This will help us get the chatbot working while we resolve the database issues.
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Dict, Any, Optional
import uuid
from datetime import datetime

# Simple in-memory storage for testing
threads = {}
messages = {}

# Initialize FastAPI app
app = FastAPI(
    title="Space Bio Backend (Simple)",
    version="0.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configure CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:8000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class ThreadCreate(BaseModel):
    seed_context: Optional[Dict[str, Any]] = None

class ThreadDTO(BaseModel):
    thread_id: str
    messages: Optional[list] = None
    context: Optional[Dict[str, Any]] = None

class AnswerRequest(BaseModel):
    q: str
    thread_id: str
    k: Optional[int] = 8
    max_tokens: Optional[int] = 800

class AnswerResponse(BaseModel):
    answer_id: str
    thread_id: str
    question: str
    answer: str
    created_at: str
    evidence_badges: Optional[Dict[str, Any]] = None
    blocks: list = []
    citations: list = []
    graph: Optional[Dict[str, Any]] = None
    debug_topic: Optional[str] = None

class SearchRequest(BaseModel):
    q: str
    filters: Optional[Dict[str, Any]] = {}
    limit: int = 10
    offset: int = 0
    thread_id: Optional[str] = None

class SearchResponse(BaseModel):
    hits: list = []
    total: int = 0
    facets: Optional[Dict[str, Any]] = None
    context: Optional[Dict[str, Any]] = None

class HealthResponse(BaseModel):
    status: str
    service: str
    version: str
    timestamp: datetime

# Routes
@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint."""
    return HealthResponse(
        status="healthy",
        service="space-bio-api-simple",
        version="1.0.0",
        timestamp=datetime.utcnow()
    )

@app.post("/api/thread", response_model=ThreadDTO)
async def create_thread(request: ThreadCreate):
    """Create a new conversation thread."""
    thread_id = str(uuid.uuid4())
    threads[thread_id] = {
        "id": thread_id,
        "created_at": datetime.utcnow(),
        "context": request.seed_context or {}
    }
    messages[thread_id] = []
    
    return ThreadDTO(
        thread_id=thread_id,
        messages=[],
        context=threads[thread_id]["context"]
    )

@app.get("/api/thread/{thread_id}", response_model=ThreadDTO)
async def get_thread(thread_id: str):
    """Get thread information and message history."""
    if thread_id not in threads:
        raise HTTPException(status_code=404, detail="Thread not found")
    
    return ThreadDTO(
        thread_id=thread_id,
        messages=messages.get(thread_id, []),
        context=threads[thread_id]["context"]
    )

@app.post("/api/answer", response_model=AnswerResponse)
async def generate_answer(request: AnswerRequest):
    """Generate AI answer for a user question."""
    if request.thread_id not in threads:
        raise HTTPException(status_code=404, detail="Thread not found")
    
    # Store user message
    user_message = {
        "id": str(uuid.uuid4()),
        "role": "user",
        "content": request.q,
        "timestamp": datetime.utcnow().isoformat()
    }
    messages[request.thread_id].append(user_message)
    
    # Generate simple AI response (mock for now)
    ai_response = f"I understand you're asking about: {request.q}. This is a mock response from the Space Bio Assistant. In a real implementation, this would be generated by the Gemini AI model."
    
    # Store AI message
    ai_message = {
        "id": str(uuid.uuid4()),
        "role": "assistant", 
        "content": ai_response,
        "timestamp": datetime.utcnow().isoformat()
    }
    messages[request.thread_id].append(ai_message)
    
    return AnswerResponse(
        answer_id=ai_message["id"],
        thread_id=request.thread_id,
        question=request.q,
        answer=ai_response,
        created_at=ai_message["timestamp"],
        evidence_badges=None,
        blocks=[],
        citations=[],
        graph=None,
        debug_topic=None
    )

@app.post("/api/search", response_model=SearchResponse)
async def search_papers(request: SearchRequest):
    """Search for research papers."""
    return SearchResponse(
        hits=[
            {
                "paper_id": "mock_paper_1",
                "title": f"Mock paper about {request.q}",
                "year": 2023,
                "score": 0.95,
                "snippet": f"This is a mock snippet about {request.q} in space biology research.",
                "sections": ["abstract", "introduction"]
            }
        ],
        total=1,
        facets=None,
        context=None
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
